{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOh9Tf3xGtO6BcqBRnrCX/P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cooolbabu/GoogleGemini101/blob/main/Gemini_LangChain/Take_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JccEMUk9U1CC",
        "outputId": "e5b614d0-6ae4-457d-b071-096f69146040"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.3/230.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U --quiet langchain-google-genai  langchain\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet langchain-google-genai"
      ],
      "metadata": {
        "id": "wynPU3KiU8Gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain.schema.prompt_template import format_document\n",
        "\n",
        "\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.prompts import HumanMessagePromptTemplate"
      ],
      "metadata": {
        "id": "SiUaA-9uVERf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# Used to securely store your API key\n",
        "\n",
        "genai.configure(api_key=userdata.get('Gemini_API_Key'))\n",
        "\n",
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "kAPG66IbVK2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# setup the gemini pro\n",
        "gemini_llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",temperature=0.3, google_api_key=userdata.get('Gemini_API_Key'))"
      ],
      "metadata": {
        "id": "6Hzoz6yJVM-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "result = gemini_llm.invoke(\"what is google vertex ai?\")\n",
        "print(result.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1stVExuV5Ss",
        "outputId": "289c29eb-b30b-4a0a-fa77-52aa2cae8705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Vertex AI is a managed machine learning platform that provides a comprehensive set of tools and services to help businesses build, deploy, and manage machine learning models. It offers a wide range of features, including:\n",
            "\n",
            "* **Model training:** Vertex AI provides a variety of tools and services to help businesses train machine learning models, including:\n",
            "    * **AutoML:** AutoML is a set of tools that allow businesses to train machine learning models without having to write any code.\n",
            "    * **Custom training:** Businesses can also use Vertex AI to train custom machine learning models using their own data and algorithms.\n",
            "* **Model deployment:** Vertex AI provides a variety of options for deploying machine learning models, including:\n",
            "    * **Model serving:** Businesses can deploy machine learning models as web services, which can be accessed by other applications.\n",
            "    * **Batch prediction:** Businesses can also use Vertex AI to perform batch predictions on large datasets.\n",
            "* **Model management:** Vertex AI provides a variety of tools and services to help businesses manage their machine learning models, including:\n",
            "    * **Model monitoring:** Businesses can use Vertex AI to monitor the performance of their machine learning models and identify any issues.\n",
            "    * **Model versioning:** Businesses can use Vertex AI to create and manage different versions of their machine learning models.\n",
            "    * **Model deletion:** Businesses can use Vertex AI to delete their machine learning models when they are no longer needed.\n",
            "\n",
            "Vertex AI is a powerful platform that can help businesses of all sizes build, deploy, and manage machine learning models. It offers a wide range of features and services that make it easy for businesses to get started with machine learning and to scale their machine learning operations as they grow.\n",
            "\n",
            "Here are some of the benefits of using Vertex AI:\n",
            "\n",
            "* **Accelerated time to value:** Vertex AI provides a variety of tools and services that can help businesses quickly and easily build, deploy, and manage machine learning models. This can help businesses to achieve faster time to value from their machine learning investments.\n",
            "* **Improved model performance:** Vertex AI provides a variety of features and services that can help businesses improve the performance of their machine learning models. This can lead to better results and more accurate predictions.\n",
            "* **Reduced costs:** Vertex AI can help businesses reduce the costs of building, deploying, and managing machine learning models. This is because Vertex AI provides a variety of tools and services that can help businesses to automate and streamline their machine learning operations.\n",
            "* **Increased agility:** Vertex AI can help businesses to become more agile in their use of machine learning. This is because Vertex AI provides a variety of tools and services that can help businesses to quickly and easily adapt their machine learning models to changing business needs.\n",
            "\n",
            "Overall, Vertex AI is a powerful platform that can help businesses of all sizes to achieve success with machine learning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example with a Prompt Template"
      ],
      "metadata": {
        "id": "2zkYGDjLXDZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.prompts import HumanMessagePromptTemplate"
      ],
      "metadata": {
        "id": "refZ8qxOXIUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gemini doesn’t support SystemMessage at the moment, but it can be added to the first human message in the row.**"
      ],
      "metadata": {
        "id": "GtFap7JvXNDh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UAyvYEzBXMKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessage(\n",
        "            content=(\n",
        "                \"return the sentiment for the given text in json fromat the sentiment value can be 'nagative','positive'\"\n",
        "            )\n",
        "        ),\n",
        "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "Vt88S57qWJ8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_message =  chat_template.format_messages(text=\"Weather today is sunny and beautiful\")"
      ],
      "metadata": {
        "id": "vAtRP9mUWcT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
        "                             temperature=0.3, convert_system_message_to_human=True,google_api_key=userdata.get('Gemini_API_Key') ) # set the convert_system_message_to_human to true\n"
      ],
      "metadata": {
        "id": "YD_Xfd2OWiG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "llm.invoke(chat_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-qCGbMGXofc",
        "outputId": "976032d9-ece2-4053-d23b-c55544040ea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='```json\\n{\\n  \"sentiment\": \"positive\"\\n}\\n```')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use Output parser to get formated output"
      ],
      "metadata": {
        "id": "L0H0gjc-X6x7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "\n",
        "parser = JsonOutputParser()\n",
        "chain = llm | parser\n",
        "\n",
        "chat_message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0y2FRH6X-XP",
        "outputId": "dceae551-e674-4245-db85-45ae471d8475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content=\"return the sentiment for the given text in json fromat the sentiment value can be 'nagative','positive'\"),\n",
              " HumanMessage(content='Weather today is sunny and beautiful')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment = chain.invoke(chat_message)\n",
        "print(sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bLGzghcYqc6",
        "outputId": "a2f7597f-1721-455d-eb3d-9e7cec1815ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sentiment': 'positive'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tagging Chain with Gemini Pro"
      ],
      "metadata": {
        "id": "6rhVQPgjY6J1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field, validator"
      ],
      "metadata": {
        "id": "3CHpg5FAYyCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tags(BaseModel):\n",
        "    sentiment: str = Field(..., enum=[\"happy\", \"neutral\", \"sad\"])\n",
        "    aggressiveness: int = Field(\n",
        "        ...,\n",
        "        description=\"describes how aggressive the statement is, the higher the number the more aggressive\",\n",
        "        enum=[1, 2, 3, 4, 5],\n",
        "    )\n",
        "    language: str = Field(\n",
        "        ..., enum=[\"spanish\", \"english\", \"french\", \"german\", \"italian\"]\n",
        "    )"
      ],
      "metadata": {
        "id": "pHUauFegY_gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set up a parser + inject instructions into the prompt template.\n",
        "parser = PydanticOutputParser(pydantic_object=Tags)"
      ],
      "metadata": {
        "id": "-LP0_n6vZAwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")"
      ],
      "metadata": {
        "id": "iYd8Z67tZL0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "chain = prompt | llm | parser\n",
        "\n",
        "chain.invoke({\"query\": \"i don't like weather today.\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCodB3ZbZAVs",
        "outputId": "a8f394b0-608f-48ae-99ff-1e63a7d77522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tags(sentiment='sad', aggressiveness=2, language='english')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Conversational chain with Gemini pro"
      ],
      "metadata": {
        "id": "jx4n5MzwlFbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "sOaz4RnjlH5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    memory=ConversationBufferMemory()\n",
        ")"
      ],
      "metadata": {
        "id": "WxldkwkblIi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conversation.predict(input=\"Hi there!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "rzRpNIPjlIZK",
        "outputId": "7074d439-9875-40ae-d49d-b7e5911138fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi there!\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello! How may I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"I'm doing well! Just having a conversation with an AI.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "TFJMgBrwlQwk",
        "outputId": "a3e6a460-3842-4a25-d61c-04c4b0ea178c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI: Hello! How may I assist you today?\n",
            "Human: I'm doing well! Just having a conversation with an AI.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"That's great to hear! I'm always happy to chat. What would you like to talk about?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
        "\n",
        "Current conversation:\n",
        "{history}\n",
        "Human: {input}\n",
        "AI Assistant:\n",
        "\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    input_variables=[\"history\", \"input\"], template=PROMPT_TEMPLATE\n",
        ")"
      ],
      "metadata": {
        "id": "cALnBBZFlQkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    prompt=PROMPT,\n",
        "    memory=ConversationBufferMemory(ai_prefix=\"AI Assistant\")\n",
        ")"
      ],
      "metadata": {
        "id": "sDYr2d8Yli37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conversation.predict(input=\"what is dojo?\")"
      ],
      "metadata": {
        "id": "6M3rAnM9li0W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "outputId": "d1931188-b19b-41d0-9357-045680486393"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: who is Gojo?\n",
            "AI Assistant: Gojo Satoru is a character in the popular anime and manga series Jujutsu Kaisen. He is a powerful sorcerer and teacher at Jujutsu High, a school that trains students to combat supernatural beings known as Curses.\n",
            "\n",
            "Gojo is known for his immense strength, unique abilities, and eccentric personality. He is also a mentor to the series' protagonist, Yuji Itadori.\n",
            "\n",
            "Here are some specific details about Gojo:\n",
            "\n",
            "* He is the strongest sorcerer in the world.\n",
            "* He has a technique called \"Limitless,\" which allows him to manipulate space and time.\n",
            "* He is known for his distinctive white hair and blue eyes.\n",
            "* He is a skilled swordsman and hand-to-hand combatant.\n",
            "* He is a popular character among fans of the series.\n",
            "\n",
            "Gojo is a complex and fascinating character who plays a vital role in Jujutsu Kaisen. His strength, abilities, and personality make him a fan favorite.\n",
            "Human: what is dojo?\n",
            "AI Assistant:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A dojo is a training hall or gymnasium for martial arts. It is a place where people go to learn and practice martial arts, such as karate, judo, aikido, and taekwondo.\\n\\nDojos typically have a large open space for training, as well as smaller rooms for private lessons or specialized training. They may also have changing rooms, showers, and other amenities.\\n\\nDojos are typically run by a martial arts instructor, or sensei, who teaches students the techniques and principles of the martial art. Students typically train in the dojo several times a week, and may also participate in competitions or tournaments.\\n\\nHere are some specific details about dojos:\\n\\n* They are typically decorated with traditional Japanese symbols and artwork.\\n* They may have a shrine or altar dedicated to the founder of the martial art.\\n* Students typically wear a uniform, or gi, while training in the dojo.\\n* Training in a dojo is typically very disciplined and structured.\\n* Dojos are often seen as a place of community and belonging for martial arts students.\\n\\nDojos play an important role in the preservation and transmission of martial arts traditions. They provide a safe and supportive environment for students to learn and practice martial arts, and help to promote the values of discipline, respect, and self-improvement.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"What is dojo javascript library?\")"
      ],
      "metadata": {
        "id": "bxYp6ecTliwM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        },
        "outputId": "b5c586ae-0c89-4caf-95f6-09956648154f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: who is Gojo?\n",
            "AI Assistant: Gojo Satoru is a character in the popular anime and manga series Jujutsu Kaisen. He is a powerful sorcerer and teacher at Jujutsu High, a school that trains students to combat supernatural beings known as Curses.\n",
            "\n",
            "Gojo is known for his immense strength, unique abilities, and eccentric personality. He is also a mentor to the series' protagonist, Yuji Itadori.\n",
            "\n",
            "Here are some specific details about Gojo:\n",
            "\n",
            "* He is the strongest sorcerer in the world.\n",
            "* He has a technique called \"Limitless,\" which allows him to manipulate space and time.\n",
            "* He is known for his distinctive white hair and blue eyes.\n",
            "* He is a skilled swordsman and hand-to-hand combatant.\n",
            "* He is a popular character among fans of the series.\n",
            "\n",
            "Gojo is a complex and fascinating character who plays a vital role in Jujutsu Kaisen. His strength, abilities, and personality make him a fan favorite.\n",
            "Human: what is dojo?\n",
            "AI Assistant: A dojo is a training hall or gymnasium for martial arts. It is a place where people go to learn and practice martial arts, such as karate, judo, aikido, and taekwondo.\n",
            "\n",
            "Dojos typically have a large open space for training, as well as smaller rooms for private lessons or specialized training. They may also have changing rooms, showers, and other amenities.\n",
            "\n",
            "Dojos are typically run by a martial arts instructor, or sensei, who teaches students the techniques and principles of the martial art. Students typically train in the dojo several times a week, and may also participate in competitions or tournaments.\n",
            "\n",
            "Here are some specific details about dojos:\n",
            "\n",
            "* They are typically decorated with traditional Japanese symbols and artwork.\n",
            "* They may have a shrine or altar dedicated to the founder of the martial art.\n",
            "* Students typically wear a uniform, or gi, while training in the dojo.\n",
            "* Training in a dojo is typically very disciplined and structured.\n",
            "* Dojos are often seen as a place of community and belonging for martial arts students.\n",
            "\n",
            "Dojos play an important role in the preservation and transmission of martial arts traditions. They provide a safe and supportive environment for students to learn and practice martial arts, and help to promote the values of discipline, respect, and self-improvement.\n",
            "Human: What is dojo javascript library?\n",
            "AI Assistant:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dojo is a free and open-source JavaScript library that provides a toolkit for building dynamic and interactive web applications. It is a modular library, meaning that you can include only the modules that you need for your project.\\n\\nDojo is known for its comprehensive set of features, including:\\n\\n* A powerful widget system for creating reusable UI components\\n* A data store system for managing and manipulating data\\n* A templating system for generating HTML markup\\n* A routing system for managing application navigation\\n* A REST API for interacting with web services\\n\\nDojo is also known for its strong community support and extensive documentation.\\n\\nHere are some specific details about Dojo:\\n\\n* It is written in JavaScript and is compatible with all major browsers.\\n* It is used by a wide range of organizations, including Fortune 500 companies and government agencies.\\n* It is licensed under the New BSD License, which is a permissive free software license.\\n\\nDojo is a powerful and versatile JavaScript library that can be used to build a wide variety of web applications. Its modular design, comprehensive feature set, and strong community support make it a popular choice for developers.\\n\\nHere are some examples of Dojo applications:\\n\\n* The New York Times website\\n* The BBC website\\n* The Weather Channel website\\n* The Intuit QuickBooks Online application\\n* The Salesforce CRM application\\n\\nDojo is a mature and stable library that is used by many large organizations. It is a good choice for developers who are looking for a powerful and flexible JavaScript library.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6RdEwOVPlisC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}