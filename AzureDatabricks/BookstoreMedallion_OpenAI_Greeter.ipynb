{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNEonbMnyrDWOV/hUwhm3jQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cooolbabu/GoogleGemini101/blob/main/AzureDatabricks/BookstoreMedallion_OpenAI_Greeter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Package installs"
      ],
      "metadata": {
        "id": "awVI93fo_PXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install openai\n",
        "%pip install PyGithub"
      ],
      "metadata": {
        "id": "SUckIMaorrfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a73ca63e-c0b8-4e2e-ff1e-cd2cdbdd24f6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.14.1-py3-none-any.whl (257 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.5/257.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.14.1\n",
            "Collecting PyGithub\n",
            "  Downloading PyGithub-2.2.0-py3-none-any.whl (350 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m350.2/350.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynacl>=1.4.0 (from PyGithub)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub) (2.31.0)\n",
            "Collecting pyjwt[crypto]>=2.4.0 (from PyGithub)\n",
            "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub) (4.10.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub) (2.0.7)\n",
            "Collecting Deprecated (from PyGithub)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (42.0.5)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pynacl>=1.4.0->PyGithub) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub) (2024.2.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->PyGithub) (1.14.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub) (2.21)\n",
            "Installing collected packages: pyjwt, Deprecated, pynacl, PyGithub\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.3.0\n",
            "    Uninstalling PyJWT-2.3.0:\n",
            "      Successfully uninstalled PyJWT-2.3.0\n",
            "Successfully installed Deprecated-1.2.14 PyGithub-2.2.0 pyjwt-2.8.0 pynacl-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports, get keys, get llm client and set model to variable MODEL_NAME"
      ],
      "metadata": {
        "id": "xXANfThOTUJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json\n",
        "import re\n",
        "from openai import OpenAI\n",
        "from pprint import pprint\n",
        "from google.colab import userdata\n",
        "from github import Github\n",
        "\n",
        "# Get the OpenAI API key from Colab secrets\n",
        "github_token=userdata.get('Github_Token')\n",
        "openai_api_key=userdata.get('OPENAI_API_KEY')\n",
        "# Initialize a GitHub instance\n",
        "g = Github(github_token)\n",
        "\n",
        "client = OpenAI(api_key=openai_api_key)\n",
        "MODEL_NAME = \"gpt-3.5-turbo\""
      ],
      "metadata": {
        "id": "HgzQz8VirhAw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Github helper functions\n",
        "* read_file_as_string()\n",
        "* check_in_file(repo_name, file_path, file_content, content_tag, branch)"
      ],
      "metadata": {
        "id": "2TKZOKLeXN1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file_as_string(file_path):\n",
        "    \"\"\"\n",
        "        Reads the file and return a string representation of the file contents\n",
        "\n",
        "        Parameters:\n",
        "            file_path (str): Filename including filepath\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            file_contents = file.read()\n",
        "        return file_contents\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File '{file_path}' not found.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "def check_in_file(repo_name, file_path, file_content, content_tag, branch):\n",
        "    \"\"\"\n",
        "        Checks if a specific file exists in a GitHub repository and updates it with new content if it does.\n",
        "        If the file does not exist, it creates a new file with the provided content.\n",
        "\n",
        "        This function operates on a specific branch named 'test'. If updating, it will commit the changes with a given content tag as the commit message.\n",
        "        In case the file needs to be created, it will also use the content tag as the commit message for the new file.\n",
        "\n",
        "        Parameters:\n",
        "        - repo_name (str): The name of the repository, formatted as 'username/repository'.\n",
        "        - file_path (str): The path to the file within the repository. This should include the file name and its extension.\n",
        "        - file_content (str): The content to be written to the file. This is used both for updating and creating the file.\n",
        "        - content_tag (str): A message associated with the commit used for updating or creating the file.\n",
        "        - branch (str): Github branch for the code\n",
        "\n",
        "        Behavior:\n",
        "        - If the file exists at the specified path, it updates the file with `file_content`, using `content_tag` as the commit message.\n",
        "        - If the file does not exist, it creates a new file at the specified path with `file_content`, also using `content_tag` as the commit message for creation.\n",
        "        - Upon successful update or creation, prints a success message indicating the action taken.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the repository\n",
        "    repo = g.get_repo(repo_name)\n",
        "\n",
        "    try:\n",
        "        # Get the contents of the file if it exists\n",
        "        file = repo.get_contents(file_path, ref=branch)\n",
        "\n",
        "        # Update the file\n",
        "        repo.update_file(file_path, content_tag, file_content, file.sha, branch=branch)\n",
        "        print(f\"File '{file_path}' updated successfully.\")\n",
        "    except:\n",
        "        # If the file doesn't exist, create it\n",
        "        print(f\"{file_path}/{file_content} does not exist\")\n",
        "        repo.create_file(file_path, content_tag, file_content, branch=branch)\n",
        "        print(f\"File '{file_path}' created successfully.\")\n",
        "\n",
        "def create_notebook(response, system_message, instructions, filename):\n",
        "    # Extract summary, code, and explanation from the response JSON\n",
        "    summary = response[\"summary\"]\n",
        "    code = response[\"code\"]\n",
        "    explanation = response[\"explanation\"]\n",
        "\n",
        "    # Create the notebook content\n",
        "    notebook_content = f\"\"\"# Databricks notebook source\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC # Summary\n",
        "# MAGIC {summary}\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC # Code (use Databricks workspace formatter to format the code)\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "{code} U+0004\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC # Explanation\n",
        "# MAGIC {explanation}\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC # GenAI Instructions\n",
        "# MAGIC * ## AI Role\n",
        "# MAGIC {system_message}\n",
        "\n",
        "# COMMAND ----------\n",
        "# MAGIC %md\n",
        "# MAGIC * ## Instructions (Try edit mode for visualizing table structure)\n",
        "# MAGIC {instructions}\n",
        "\"\"\"\n",
        "\n",
        "    # Write the notebook content to a file\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(notebook_content)\n",
        "\n",
        "    print(f\"Notebook '{filename}' has been created.\")\n",
        "\n",
        "    return notebook_content"
      ],
      "metadata": {
        "id": "U6zhOVp3rhDW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "def convert_str_to_dict(s):\n",
        "    try:\n",
        "        d = ast.literal_eval(s)\n",
        "        if isinstance(d, dict):\n",
        "            return d\n",
        "        else:\n",
        "            raise ValueError(\"Input is not a valid dictionary string\")\n",
        "    except (ValueError, SyntaxError):\n",
        "        raise ValueError(\"Input is not a valid dictionary string\")\n",
        "\n",
        "import string\n",
        "\n",
        "def strip_control_characters_old(s):\n",
        "    # Create a translation table that maps all control characters to None\n",
        "    control_chars = dict.fromkeys(range(0x00, 0x20), ' ')\n",
        "    control_chars.update(dict.fromkeys(range(0x7f, 0xa0), ' '))\n",
        "\n",
        "    # Translate the string using the translation table\n",
        "    cleaned_str = s.translate(dict.fromkeys(control_chars, ' '))\n",
        "\n",
        "    return cleaned_str\n",
        "\n",
        "def strip_control_characters(s):\n",
        "    # Create a translation table that maps all control characters and special characters to a space ' '\n",
        "    control_chars = dict.fromkeys(range(0x00, 0x09), ' ')  # Exclude \\n, \\r, \\f\n",
        "    control_chars.update(dict.fromkeys(range(0x0B, 0x0C), ' '))\n",
        "    control_chars.update(dict.fromkeys(range(0x0E, 0x20), ' '))\n",
        "    control_chars.update(dict.fromkeys(range(0x7f, 0xa0), ' '))\n",
        "    special_chars = dict.fromkeys(map(ord, string.punctuation.replace('\\n', '').replace('\\r', '').replace('\\f', '')), ' ')\n",
        "    control_chars.update(special_chars)\n",
        "\n",
        "    # Translate the string using the translation table\n",
        "    cleaned_str = s.translate(control_chars)"
      ],
      "metadata": {
        "id": "NOGlMd278egD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "1.   System Message\n",
        "2.   User Message\n",
        "\n"
      ],
      "metadata": {
        "id": "TqsXQmSVUKDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"\"\"\n",
        "You are  Azure Databricks data engineer.\n",
        "    - You will be given tasks and asked to write pyspark code.\n",
        "    - You will use best practices for writing code.\n",
        "    - Your response will be in JSON format with keys \"summary\", \"code\", \"explanation\".\n",
        "  \"\"\".strip()\n",
        "\n",
        "#user_message_content = read_file_as_string(\"./BookstorePrompt.txt\")\n",
        "#print(user_message_content)"
      ],
      "metadata": {
        "id": "CXd8CCYOLCBN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make the call to LLMs"
      ],
      "metadata": {
        "id": "_MDSbrT9UpOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the message with variables\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a sarcastic greeter with a great sense of humor\"},\n",
        "        {\"role\": \"user\", \"content\": \"Say this is a test\"}]\n",
        ")\n",
        "\n",
        "# Assuming you have a client setup for interaction. Ensure to configure your OpenAI client appropriately.\n",
        "\n"
      ],
      "metadata": {
        "id": "DAKT9wxMrhGK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = response.content[0].text"
      ],
      "metadata": {
        "id": "qHbV2EzkL3qO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "jNUavIntPBIc",
        "outputId": "3374a3fa-9e59-4b30-caca-899aa8871974",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-93NivuIPglB8fdAi3VbNM4lsH6AzM', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"summary\": \"Creating Orders table containing order_id, customer_id, books, total_quantity\",\\n  \"code\": \"CREATE TABLE Orders (order_id INT, customer_id INT, books STRING, total_quantity INT)\",\\n  \"explanation\": \"In this code snippet, we are creating a table named \\'Orders\\' with columns order_id (INT), customer_id (INT), books (STRING), and total_quantity (INT) to store order details.\"\\n}', role='assistant', function_call=None, tool_calls=None))], created=1710593205, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_4f2ebda25a', usage=CompletionUsage(completion_tokens=93, prompt_tokens=83, total_tokens=176))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Chat id: {response.id}\" )\n",
        "print(response.choices[0].message);\n",
        "print(response.usage);"
      ],
      "metadata": {
        "id": "nNNcvN2dNLAF",
        "outputId": "4dc1305e-c9bd-4d4c-de32-8e1faab43864",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chat id: chatcmpl-93NHpWmRCF3tnio7QOBjixLj6tfyV\n",
            "ChatCompletionMessage(content=\"Oh wow, a test you say? How thrilling! I've been waiting all day to be tested on my vast knowledge of all things sarcasm and wit. Let the fun begin!\", role='assistant', function_call=None, tool_calls=None)\n",
            "CompletionUsage(completion_tokens=37, prompt_tokens=29, total_tokens=66)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response = client.chat.completions.create(\n",
        "   model=MODEL_NAME,\n",
        "  response_format={ \"type\": \"json_object\" },\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a sarcastic greeter with a great sense of humor. reponses must be in json format\"},\n",
        "        {\"role\": \"user\", \"content\": \"Say this is a test\"}]\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lBSMIX4NdIc",
        "outputId": "7c8392a6-6d50-41ad-b5c1-fb7f71568ec3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"response\": \"Oh joy, a test! Let's see if I can impress you with my vast knowledge and witty responses.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t2zDak8BSl73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response = client.chat.completions.create(\n",
        "   model=MODEL_NAME,\n",
        "  response_format={ \"type\": \"json_object\" },\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a sarcastic greeter with a great sense of humor. reponses must be in json format\"},\n",
        "        {\"role\": \"user\", \"content\": \"Say this is a test\"}]\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "outputId": "7c8392a6-6d50-41ad-b5c1-fb7f71568ec3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ucAuamqSme6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"response\": \"Oh joy, a test! Let's see if I can impress you with my vast knowledge and witty responses.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response = client.chat.completions.create(\n",
        "   model=MODEL_NAME,\n",
        "  response_format={ \"type\": \"json_object\" },\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": \"Create a Orders table containing order_id, customer_id, books, total_quantity\"}]\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "Vyfr23oaSxvI",
        "outputId": "fa2d350b-d5fc-4909-ee62-d32965a5a190",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"summary\": \"Creating Orders table containing order_id, customer_id, books, total_quantity\",\n",
            "  \"code\": \"CREATE TABLE Orders (order_id INT, customer_id INT, books STRING, total_quantity INT)\",\n",
            "  \"explanation\": \"In this code snippet, we are creating a table named 'Orders' with columns order_id (INT), customer_id (INT), books (STRING), and total_quantity (INT) to store order details.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validate response from LLM"
      ],
      "metadata": {
        "id": "MOTbodyRUt55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pMjSEaIcLrNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stripped_message = strip_control_characters_old(message)\n",
        "#print(stripped_message)\n",
        "print(message)\n"
      ],
      "metadata": {
        "id": "Eiv8FviXrhNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45909c43-4f91-4bd3-9b2c-2a4cd9cd80ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is the PySpark program for Azure Databricks using the Medallion framework based on your instructions:\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"summary\": \"The PySpark program ingests data into orders_bronze table using Autoloader, processes it into orders_silver table by joining with customers table, and aggregates sales data into sales_by_author table. It follows the Medallion architecture and uses best practices for variable naming, checkpointing, and schema management.\",\n",
            "  \"code\": \"from pyspark.sql import SparkSession\n",
            "from pyspark.sql.functions import input_file_name, current_timestamp, from_json, col, explode\n",
            "\n",
            "# Initialize Spark session\n",
            "spark = SparkSession.builder \\\n",
            "    .appName(\\\"BookstoreETL\\\") \\\n",
            "    .getOrCreate()\n",
            "\n",
            "# Define variables for table names and locations\n",
            "orders_bronze_table = \\\"orders_bronze\\\"\n",
            "orders_silver_table = \\\"orders_silver\\\"\n",
            "sales_by_author_table = \\\"sales_by_author\\\"\n",
            "customers_table = \\\"customers\\\"\n",
            "books_table = \\\"books\\\"\n",
            "\n",
            "checkpoint_root = \\\"dbfs:/mnt/bookstore/checkpoints/\\\"\n",
            "schema_root = \\\"dbfs:/mnt/bookstore/schemas/\\\"\n",
            "\n",
            "# Part 1: Ingesting Data into Orders_Bronze Table\n",
            "orders_raw_path = \\\"dbfs:/mnt/bookstore/orders-raw\\\"\n",
            "orders_bronze_checkpoint = checkpoint_root + \\\"orders_bronze\\\"\n",
            "\n",
            "orders_bronze_stream = spark.readStream \\\n",
            "    .format(\\\"cloudFiles\\\") \\\n",
            "    .option(\\\"cloudFiles.format\\\", \\\"parquet\\\") \\\n",
            "    .option(\\\"cloudFiles.schemaLocation\\\", schema_root + \\\"orders_bronze\\\") \\\n",
            "    .load(orders_raw_path) \\\n",
            "    .withColumn(\\\"file_name\\\", input_file_name()) \\\n",
            "    .withColumn(\\\"processed_timestamp\\\", current_timestamp())\n",
            "\n",
            "orders_bronze_stream.writeStream \\\n",
            "    .format(\\\"delta\\\") \\\n",
            "    .outputMode(\\\"append\\\") \\\n",
            "    .option(\\\"checkpointLocation\\\", orders_bronze_checkpoint) \\\n",
            "    .trigger(availableNow=True) \\\n",
            "    .toTable(orders_bronze_table)\n",
            "\n",
            "# Part 2: Writing Orders_Silver Table from Orders_Bronze and Customers\n",
            "orders_silver_checkpoint = checkpoint_root + \\\"orders_silver\\\"\n",
            "\n",
            "orders_bronze_streaming_view = spark.readStream \\\n",
            "    .table(orders_bronze_table) \\\n",
            "    .createOrReplaceTempView(\\\"orders_bronze_streaming_view\\\")\n",
            "\n",
            "customers_df = spark.table(customers_table)\n",
            "\n",
            "orders_silver_stream = spark.sql(\\\"\\\"\\\"\n",
            "    SELECT \n",
            "        o.order_id,\n",
            "        o.quantity,\n",
            "        o.customer_id,\n",
            "        o.books,\n",
            "        from_json(c.profile, 'first_name STRING, last_name STRING').first_name AS f_name,\n",
            "        from_json(c.profile, 'first_name STRING, last_name STRING').last_name AS l_name,\n",
            "        date_format(from_unixtime(o.order_timestamp / 1000), 'yyyy-MM-dd') AS order_date\n",
            "    FROM orders_bronze_streaming_view o\n",
            "    JOIN customers c ON o.customer_id = c.customer_id\n",
            "    WHERE o.quantity > 0\n",
            "\\\"\\\"\\\")\n",
            "\n",
            "orders_silver_stream.writeStream \\\n",
            "    .format(\\\"delta\\\") \\\n",
            "    .outputMode(\\\"append\\\") \\\n",
            "    .option(\\\"checkpointLocation\\\", orders_silver_checkpoint) \\\n",
            "    .trigger(availableNow=True) \\\n",
            "    .toTable(orders_silver_table)\n",
            "\n",
            "# Part 3: Populating Sales_by_Author Table from Orders_Silver\n",
            "sales_by_author_checkpoint = checkpoint_root + \\\"sales_by_author\\\"\n",
            "\n",
            "orders_silver_stream = spark.readStream \\\n",
            "    .table(orders_silver_table)\n",
            "\n",
            "books_df = spark.table(books_table)\n",
            "\n",
            "sales_by_author_stream = orders_silver_stream \\\n",
            "    .select(\\\"books\\\") \\\n",
            "    .withColumn(\\\"book\\\", explode(\\\"books\\\")) \\\n",
            "    .select(\\\"book.book_id\\\", \\\"book.quantity\\\", \\\"book.subtotal\\\") \\\n",
            "    .join(books_df, \\\"book_id\\\") \\\n",
            "    .groupBy(\\\"author\\\") \\\n",
            "    .agg(\n",
            "        sum(\\\"subtotal\\\").alias(\\\"Total_Sales_Amount\\\"),\n",
            "        sum(\\\"quantity\\\").alias(\\\"Total_Sales_Quantity\\\")\n",
            "    )\n",
            "\n",
            "sales_by_author_stream.writeStream \\\n",
            "    .format(\\\"delta\\\") \\\n",
            "    .outputMode(\\\"complete\\\") \\\n",
            "    .option(\\\"checkpointLocation\\\", sales_by_author_checkpoint) \\\n",
            "    .trigger(availableNow=True) \\\n",
            "    .toTable(sales_by_author_table)\n",
            "\",\n",
            "  \"explanation\": \"The PySpark program follows the Medallion architecture and is divided into three parts:\n",
            "\n",
            "1. Ingesting Data into Orders_Bronze Table:\n",
            "   - It uses Autoloader to read parquet files from the orders-raw directory.\n",
            "   - Appends file_name and processed_timestamp columns using input_file_name() and current_timestamp() functions.\n",
            "   - Writes the stream to the orders_bronze table using append mode and specifies the checkpoint location.\n",
            "   - Uses .trigger(availableNow=True) and toTable() function.\n",
            "   - Leverages Autoloader's schema evolution functionality.\n",
            "\n",
            "2. Writing Orders_Silver Table from Orders_Bronze and Customers:\n",
            "   - Reads from the orders_bronze table as a stream and creates a temporary streaming view.\n",
            "   - Loads the customers table.\n",
            "   - Performs a SQL join between the streaming view and customers table on customer_id.\n",
            "   - Extracts first_name and last_name from the profile JSON column.\n",
            "   - Selects only rows with quantity greater than 0.\n",
            "   - Writes the joined data to the orders_silver table using writeStream with append mode and specifies the checkpoint location.\n",
            "   - Uses .trigger(availableNow=True) and toTable() function.\n",
            "\n",
            "3. Populating Sales_by_Author Table from Orders_Silver:\n",
            "   - Reads from the orders_silver table as a stream.\n",
            "   - Explodes the books array to flatten book details and selects necessary columns.\n",
            "   - Joins with the books table to enrich book items with author information.\n",
            "   - Groups by author and aggregates to calculate Total_Sales_Amount and Total_Sales_Quantity.\n",
            "   - Writes the aggregated data to the sales_by_author table using writeStream with complete mode and specifies the checkpoint location.\n",
            "   - Uses .trigger(availableNow=True) and toTable() function.\n",
            "\n",
            "The program follows best practices by using meaningful variable names, storing table names and locations in variables, and organizing checkpoint and schema locations. It demonstrates the use of Autoloader, streaming reads and writes, SQL joins, JSON parsing, and aggregations in PySpark.\"\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_contents = create_notebook(json.loads(stripped_message), system_message, user_message_content, \"orders_bronze_notebook-t2.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "F3ZTQpLg3RiI",
        "outputId": "82d7de23-b91c-4256-ffa3-bfce1e78275a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "Expecting value: line 1 column 1 (char 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-c0ea86960f4f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile_contents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstripped_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msystem_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_message_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"orders_bronze_notebook-t2.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(file_contents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "wjTxx8GwZV6k",
        "outputId": "6d4729e7-39f6-436f-c6d0-9e7d2f066ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'file_contents' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-bfdaf289d525>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'file_contents' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check into Github\n",
        "*   repository : \"cooolbabu/GoogleGemini101\"\n",
        "*   filename : \"AzureDatabricks/filename\" - specify actual filename\n",
        "*   filecontent: Contents of the file to check in\n",
        "*   tag_name: give a comment. It will show in Github\n",
        "* branch: branch name to check into. Ensure that branch already exists\n",
        "          Future TODO: if branch doesn't exist (notify, ask, process)\n",
        "\n"
      ],
      "metadata": {
        "id": "zn-veyM-U19x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "check_in_file(repo_name=\"cooolbabu/GoogleGemini101\",\n",
        "              file_path=\"AzureDatabricks/ConfigureDB/create_order_table-t1.py\",\n",
        "              file_content=file_contents,\n",
        "              content_tag='creating orders table added control characters t5',\n",
        "              branch=\"pyspark-genai-t2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ELMDUfXRBi7V",
        "outputId": "b9b8e418-24ec-4065-8859-7bd6f936627b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'AzureDatabricks/ConfigureDB/create_order_table-t1.py' updated successfully.\n"
          ]
        }
      ]
    }
  ]
}