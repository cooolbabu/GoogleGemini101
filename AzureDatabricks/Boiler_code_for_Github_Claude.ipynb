{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNV8sv+NW3pM/PkMg3qzfyl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cooolbabu/GoogleGemini101/blob/main/AzureDatabricks/Boiler_code_for_Github_Claude.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Having issues with responses. Need to fix the json formatted response"
      ],
      "metadata": {
        "id": "dxsMvdHSwv3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Package installs"
      ],
      "metadata": {
        "id": "awVI93fo_PXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install anthropic\n",
        "%pip install PyGithub"
      ],
      "metadata": {
        "id": "SUckIMaorrfl",
        "outputId": "4647c143-0de9-4a5e-d894-ec2287c02f6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.20.0-py3-none-any.whl (850 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m850.5/850.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from anthropic)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->anthropic)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->anthropic)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.16.3)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.0.7)\n",
            "Installing collected packages: h11, httpcore, httpx, anthropic\n",
            "Successfully installed anthropic-0.20.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0\n",
            "Collecting PyGithub\n",
            "  Downloading PyGithub-2.2.0-py3-none-any.whl (350 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m350.2/350.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynacl>=1.4.0 (from PyGithub)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub) (2.31.0)\n",
            "Collecting pyjwt[crypto]>=2.4.0 (from PyGithub)\n",
            "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub) (4.10.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub) (2.0.7)\n",
            "Collecting Deprecated (from PyGithub)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (42.0.5)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pynacl>=1.4.0->PyGithub) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub) (2024.2.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->PyGithub) (1.14.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub) (2.21)\n",
            "Installing collected packages: pyjwt, Deprecated, pynacl, PyGithub\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.3.0\n",
            "    Uninstalling PyJWT-2.3.0:\n",
            "      Successfully uninstalled PyJWT-2.3.0\n",
            "Successfully installed Deprecated-1.2.14 PyGithub-2.2.0 pyjwt-2.8.0 pynacl-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports, get keys, get llm client and set model to variable MODEL_NAME"
      ],
      "metadata": {
        "id": "xXANfThOTUJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from anthropic import Anthropic\n",
        "import json\n",
        "import re\n",
        "from pprint import pprint\n",
        "from google.colab import userdata\n",
        "from github import Github\n",
        "\n",
        "# Get the OpenAI API key from Colab secrets\n",
        "github_token=userdata.get('Github_Token')\n",
        "claude_api_key=userdata.get('Claude_api_key')\n",
        "# Initialize a GitHub instance\n",
        "g = Github(github_token)\n",
        "\n",
        "client = Anthropic(api_key=claude_api_key)\n",
        "MODEL_NAME = \"claude-3-opus-20240229\""
      ],
      "metadata": {
        "id": "HgzQz8VirhAw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Github helper functions\n",
        "* read_file_as_string()\n",
        "* check_in_file(repo_name, file_path, file_content, content_tag, branch)"
      ],
      "metadata": {
        "id": "2TKZOKLeXN1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file_as_string(file_path):\n",
        "    \"\"\"\n",
        "        Reads the file and return a string representation of the file contents\n",
        "\n",
        "        Parameters:\n",
        "            file_path (str): Filename including filepath\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            file_contents = file.read()\n",
        "        return file_contents\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File '{file_path}' not found.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "def check_in_file(repo_name, file_path, file_content, content_tag, branch):\n",
        "    \"\"\"\n",
        "        Checks if a specific file exists in a GitHub repository and updates it with new content if it does.\n",
        "        If the file does not exist, it creates a new file with the provided content.\n",
        "\n",
        "        This function operates on a specific branch named 'test'. If updating, it will commit the changes with a given content tag as the commit message.\n",
        "        In case the file needs to be created, it will also use the content tag as the commit message for the new file.\n",
        "\n",
        "        Parameters:\n",
        "        - repo_name (str): The name of the repository, formatted as 'username/repository'.\n",
        "        - file_path (str): The path to the file within the repository. This should include the file name and its extension.\n",
        "        - file_content (str): The content to be written to the file. This is used both for updating and creating the file.\n",
        "        - content_tag (str): A message associated with the commit used for updating or creating the file.\n",
        "        - branch (str): Github branch for the code\n",
        "\n",
        "        Behavior:\n",
        "        - If the file exists at the specified path, it updates the file with `file_content`, using `content_tag` as the commit message.\n",
        "        - If the file does not exist, it creates a new file at the specified path with `file_content`, also using `content_tag` as the commit message for creation.\n",
        "        - Upon successful update or creation, prints a success message indicating the action taken.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the repository\n",
        "    repo = g.get_repo(repo_name)\n",
        "\n",
        "    try:\n",
        "        # Get the contents of the file if it exists\n",
        "        file = repo.get_contents(file_path, ref=branch)\n",
        "\n",
        "        # Update the file\n",
        "        repo.update_file(file_path, content_tag, file_content, file.sha, branch=branch)\n",
        "        print(f\"File '{file_path}' updated successfully.\")\n",
        "    except:\n",
        "        # If the file doesn't exist, create it\n",
        "        print(f\"{file_path}/{file_content} does not exist\")\n",
        "        repo.create_file(file_path, content_tag, file_content, branch=branch)\n",
        "        print(f\"File '{file_path}' created successfully.\")\n",
        "\n",
        "def create_notebook(response, system_message, instructions, filename):\n",
        "    # Extract summary, code, and explanation from the response JSON\n",
        "    summary = response[\"summary\"]\n",
        "    code = response[\"code\"]\n",
        "    explanation = response[\"explanation\"]\n",
        "\n",
        "    # Create the notebook content\n",
        "    notebook_content = f\"\"\"# Databricks notebook source\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC # Summary\n",
        "# MAGIC {summary}\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC # Code (use Databricks workspace formatter to format the code)\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "{code} U+0004\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC # Explanation\n",
        "# MAGIC {explanation}\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC # GenAI Instructions\n",
        "# MAGIC * ## AI Role\n",
        "# MAGIC {system_message}\n",
        "\n",
        "# COMMAND ----------\n",
        "# MAGIC %md\n",
        "# MAGIC * ## Instructions (Try edit mode for visualizing table structure)\n",
        "# MAGIC {instructions}\n",
        "\"\"\"\n",
        "\n",
        "    # Write the notebook content to a file\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(notebook_content)\n",
        "\n",
        "    print(f\"Notebook '{filename}' has been created.\")\n",
        "\n",
        "    return notebook_content"
      ],
      "metadata": {
        "id": "U6zhOVp3rhDW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "def convert_str_to_dict(s):\n",
        "    try:\n",
        "        d = ast.literal_eval(s)\n",
        "        if isinstance(d, dict):\n",
        "            return d\n",
        "        else:\n",
        "            raise ValueError(\"Input is not a valid dictionary string\")\n",
        "    except (ValueError, SyntaxError):\n",
        "        raise ValueError(\"Input is not a valid dictionary string\")\n",
        "\n",
        "import string\n",
        "\n",
        "def strip_control_characters_old(s):\n",
        "    # Create a translation table that maps all control characters to None\n",
        "    control_chars = dict.fromkeys(range(0x00, 0x20), ' ')\n",
        "    control_chars.update(dict.fromkeys(range(0x7f, 0xa0), ' '))\n",
        "\n",
        "    # Translate the string using the translation table\n",
        "    cleaned_str = s.translate(dict.fromkeys(control_chars, ' '))\n",
        "\n",
        "    return cleaned_str\n",
        "\n",
        "def strip_control_characters(s):\n",
        "    # Create a translation table that maps all control characters and special characters to a space ' '\n",
        "    control_chars = dict.fromkeys(range(0x00, 0x09), ' ')  # Exclude \\n, \\r, \\f\n",
        "    control_chars.update(dict.fromkeys(range(0x0B, 0x0C), ' '))\n",
        "    control_chars.update(dict.fromkeys(range(0x0E, 0x20), ' '))\n",
        "    control_chars.update(dict.fromkeys(range(0x7f, 0xa0), ' '))\n",
        "    special_chars = dict.fromkeys(map(ord, string.punctuation.replace('\\n', '').replace('\\r', '').replace('\\f', '')), ' ')\n",
        "    control_chars.update(special_chars)\n",
        "\n",
        "    # Translate the string using the translation table\n",
        "    cleaned_str = s.translate(control_chars)"
      ],
      "metadata": {
        "id": "NOGlMd278egD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "1.   System Message\n",
        "2.   User Message\n",
        "\n"
      ],
      "metadata": {
        "id": "TqsXQmSVUKDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"\"\"\n",
        "You are  Azure Databricks data engineer.\n",
        "    You will be given tasks and asked to write pyspark code.\n",
        "    You will use best practices for writing code.\n",
        "    Your response will be in JSON format with keys \"summary\", \"code\", \"explanation\".\n",
        "    Do not include introductory line the response.\n",
        "  \"\"\".strip()\n",
        "\n",
        "\n",
        "user_message_content = \"\"\"\n",
        "  I will give you schema for a table. Your task is to provide pyspark code to create the table.\n",
        "  orders_bronze table schema\n",
        "  root\n",
        "  |-- order_id: string (nullable = true)\n",
        "  |-- order_timestamp: long (nullable = true)\n",
        "  |-- customer_id: string (nullable = true)\n",
        "  |-- quantity: long (nullable = true)\n",
        "  |-- total: integer (nullable = true)\n",
        "  |-- books: array (nullable = true)\n",
        "  |    |-- element: struct (containsNull = true)\n",
        "  |    |    |-- book_id: string (nullable = true)\n",
        "  |    |    |-- quantity: integer (nullable = true)\n",
        "  |    |    |-- subtotal: long (nullable = true)\n",
        "  |-- _rescued_data: string (nullable = true)\n",
        "  |-- file_name: string (nullable = true)\n",
        "  |-- processed_timestamp: timestamp (nullable = true)\n",
        "  \"\"\".strip()"
      ],
      "metadata": {
        "id": "CXd8CCYOLCBN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make the call to LLMs"
      ],
      "metadata": {
        "id": "_MDSbrT9UpOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the message with variables\n",
        "response = client.messages.create(\n",
        "    model=\"claude-3-opus-20240229\",\n",
        "    max_tokens=1000,\n",
        "    temperature=0,\n",
        "    system=system_message,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": user_message_content}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Assuming you have a client setup for interaction. Ensure to configure your OpenAI client appropriately.\n",
        "\n",
        "message = response.content[0].text"
      ],
      "metadata": {
        "id": "DAKT9wxMrhGK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validate response from LLM"
      ],
      "metadata": {
        "id": "MOTbodyRUt55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(response))"
      ],
      "metadata": {
        "id": "54NY8U-rzqt6",
        "outputId": "3dbdd8b2-f2cc-40d2-97dd-037d12a0216a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'anthropic.types.message.Message'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)\n",
        "resp_in_json = json.loads(message)"
      ],
      "metadata": {
        "id": "8qUY0zFPy1tf",
        "outputId": "a4d7da18-2c7c-4b49-d99e-60c25a9dc2e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message(id='msg_01Y8pLFkfJgh8or3PiEpP66d', content=[ContentBlock(text='{\\n  \"summary\": \"The code creates a schema for the orders_bronze table using StructType and StructField classes from pyspark.sql.types, and then creates a DataFrame using the createDataFrame method with an empty RDD and the defined schema.\",\\n  \"code\": \"from pyspark.sql.types import StructType, StructField, StringType, LongType, IntegerType, ArrayType, TimestampType\\n\\nschema = StructType([\\n    StructField(\\\\\"order_id\\\\\", StringType(), True),\\n    StructField(\\\\\"order_timestamp\\\\\", LongType(), True),\\n    StructField(\\\\\"customer_id\\\\\", StringType(), True),\\n    StructField(\\\\\"quantity\\\\\", LongType(), True),\\n    StructField(\\\\\"total\\\\\", IntegerType(), True),\\n    StructField(\\\\\"books\\\\\", ArrayType(\\n        StructType([\\n            StructField(\\\\\"book_id\\\\\", StringType(), True),\\n            StructField(\\\\\"quantity\\\\\", IntegerType(), True),\\n            StructField(\\\\\"subtotal\\\\\", LongType(), True)\\n        ])\\n    ), True),\\n    StructField(\\\\\"_rescued_data\\\\\", StringType(), True),\\n    StructField(\\\\\"file_name\\\\\", StringType(), True),\\n    StructField(\\\\\"processed_timestamp\\\\\", TimestampType(), True)\\n])\\n\\norders_bronze = spark.createDataFrame([], schema)\",\\n  \"explanation\": \"1. The necessary classes (StructType, StructField, StringType, LongType, IntegerType, ArrayType, TimestampType) are imported from pyspark.sql.types to define the schema.\\n\\n2. The schema is defined using StructType, which takes a list of StructField objects. Each StructField represents a column in the table, specifying the column name, data type, and nullability.\\n\\n3. The \\\\\"books\\\\\" column is defined as an ArrayType containing a StructType, which represents the nested structure of the books array.\\n\\n4. Finally, the orders_bronze DataFrame is created using the createDataFrame method of the SparkSession object (spark). It takes an empty RDD ([]) and the defined schema as arguments.\\n\\nThis code sets up the schema for the orders_bronze table, which can be used to read data into a DataFrame with the specified structure.\"\\n}', type='text')], model='claude-3-opus-20240229', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=299, output_tokens=542))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "Invalid control character at: line 3 column 126 (char 366)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-364c3f9af59f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresp_in_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Invalid control character at: line 3 column 126 (char 366)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1eFFFkINy1pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5T2C8f4Ly1bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stripped_message = strip_control_characters(message)\n"
      ],
      "metadata": {
        "id": "Eiv8FviXrhNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_contents = create_notebook(json.loads(stripped_message), system_message, user_message_content, \"orders_bronze_notebook-t2.py\")"
      ],
      "metadata": {
        "id": "F3ZTQpLg3RiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(file_contents)"
      ],
      "metadata": {
        "id": "wjTxx8GwZV6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check into Github\n",
        "*   repository : \"cooolbabu/GoogleGemini101\"\n",
        "*   filename : \"AzureDatabricks/filename\" - specify actual filename\n",
        "*   filecontent: Contents of the file to check in\n",
        "*   tag_name: give a comment. It will show in Github\n",
        "* branch: branch name to check into. Ensure that branch already exists\n",
        "          Future TODO: if branch doesn't exist (notify, ask, process)\n",
        "\n"
      ],
      "metadata": {
        "id": "zn-veyM-U19x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "check_in_file(repo_name=\"cooolbabu/GoogleGemini101\",\n",
        "              file_path=\"AzureDatabricks/ConfigureDB/create_order_table-t1.py\",\n",
        "              file_content=file_contents,\n",
        "              content_tag='creating orders table added control characters t5',\n",
        "              branch=\"pyspark-genai-t2\")"
      ],
      "metadata": {
        "id": "ELMDUfXRBi7V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}