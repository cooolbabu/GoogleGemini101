{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOAGTOOtVud3ZRUaczrjWZO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cooolbabu/GoogleGemini101/blob/main/AzureDatabricks/Boiler_code_for_Github_Claude.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About this notebook\n",
        "- We are using Claude to generate create table code\n",
        "- Generated is stored in Github\n",
        "- This an example of Claudes failure"
      ],
      "metadata": {
        "id": "2W6wgdoaRtaw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Package installs"
      ],
      "metadata": {
        "id": "awVI93fo_PXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install anthropic\n",
        "%pip install PyGithub"
      ],
      "metadata": {
        "id": "SUckIMaorrfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports, get keys, get llm client and set model to variable MODEL_NAME"
      ],
      "metadata": {
        "id": "xXANfThOTUJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from anthropic import Anthropic\n",
        "import json\n",
        "import re\n",
        "from pprint import pprint\n",
        "from google.colab import userdata\n",
        "from github import Github\n",
        "\n",
        "# Get the OpenAI API key from Colab secrets\n",
        "github_token=userdata.get('Github_Token')\n",
        "claude_api_key=userdata.get('Claude_api_key')\n",
        "# Initialize a GitHub instance\n",
        "g = Github(github_token)\n",
        "\n",
        "client = Anthropic(api_key=claude_api_key)\n",
        "MODEL_NAME = \"claude-3-opus-20240229\""
      ],
      "metadata": {
        "id": "HgzQz8VirhAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Github helper functions\n",
        "* read_file_as_string()\n",
        "* check_in_file(repo_name, file_path, file_content, content_tag, branch)"
      ],
      "metadata": {
        "id": "2TKZOKLeXN1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file_as_string(file_path):\n",
        "    \"\"\"\n",
        "        Reads the file and return a string representation of the file contents\n",
        "\n",
        "        Parameters:\n",
        "            file_path (str): Filename including filepath\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            file_contents = file.read()\n",
        "        return file_contents\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File '{file_path}' not found.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "def check_in_file(repo_name, file_path, file_content, content_tag, branch):\n",
        "    \"\"\"\n",
        "        Checks if a specific file exists in a GitHub repository and updates it with new content if it does.\n",
        "        If the file does not exist, it creates a new file with the provided content.\n",
        "\n",
        "        This function operates on a specific branch named 'test'. If updating, it will commit the changes with a given content tag as the commit message.\n",
        "        In case the file needs to be created, it will also use the content tag as the commit message for the new file.\n",
        "\n",
        "        Parameters:\n",
        "        - repo_name (str): The name of the repository, formatted as 'username/repository'.\n",
        "        - file_path (str): The path to the file within the repository. This should include the file name and its extension.\n",
        "        - file_content (str): The content to be written to the file. This is used both for updating and creating the file.\n",
        "        - content_tag (str): A message associated with the commit used for updating or creating the file.\n",
        "        - branch (str): Github branch for the code\n",
        "\n",
        "        Behavior:\n",
        "        - If the file exists at the specified path, it updates the file with `file_content`, using `content_tag` as the commit message.\n",
        "        - If the file does not exist, it creates a new file at the specified path with `file_content`, also using `content_tag` as the commit message for creation.\n",
        "        - Upon successful update or creation, prints a success message indicating the action taken.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the repository\n",
        "    repo = g.get_repo(repo_name)\n",
        "\n",
        "    try:\n",
        "        # Get the contents of the file if it exists\n",
        "        file = repo.get_contents(file_path, ref=branch)\n",
        "\n",
        "        # Update the file\n",
        "        repo.update_file(file_path, content_tag, file_content, file.sha, branch=branch)\n",
        "        print(f\"File '{file_path}' updated successfully.\")\n",
        "    except:\n",
        "        # If the file doesn't exist, create it\n",
        "        print(f\"{file_path}/{file_content} does not exist\")\n",
        "        repo.create_file(file_path, content_tag, file_content, branch=branch)\n",
        "        print(f\"File '{file_path}' created successfully.\")\n",
        "\n",
        "def create_notebook(response, system_message, instructions, filename):\n",
        "    # Extract summary, code, and explanation from the response JSON\n",
        "    summary = response[\"summary\"]\n",
        "    code = response[\"code\"]\n",
        "    explanation = response[\"explanation\"]\n",
        "\n",
        "    # Create the notebook content\n",
        "    notebook_content = f\"\"\"# Databricks notebook source\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC # Summary\n",
        "# MAGIC {summary}\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC # Code (use Databricks workspace formatter to format the code)\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "{code}\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC # Explanation\n",
        "# MAGIC {explanation}\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC # GenAI Instructions\n",
        "# MAGIC * ## AI Role\n",
        "# MAGIC {system_message}\n",
        "\n",
        "# COMMAND ----------\n",
        "# MAGIC %md\n",
        "# MAGIC * ## Instructions (Try edit mode for visualizing table structure)\n",
        "# MAGIC {instructions}\n",
        "\"\"\"\n",
        "\n",
        "    # Write the notebook content to a file\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(notebook_content)\n",
        "\n",
        "    print(f\"Notebook '{filename}' has been created.\")\n",
        "\n",
        "    return notebook_content"
      ],
      "metadata": {
        "id": "U6zhOVp3rhDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "def convert_str_to_dict(s):\n",
        "    try:\n",
        "        d = ast.literal_eval(s)\n",
        "        if isinstance(d, dict):\n",
        "            return d\n",
        "        else:\n",
        "            raise ValueError(\"Input is not a valid dictionary string\")\n",
        "    except (ValueError, SyntaxError):\n",
        "        raise ValueError(\"Input is not a valid dictionary string\")\n",
        "\n",
        "import string\n",
        "\n",
        "def strip_control_characters_old(s):\n",
        "    # Create a translation table that maps all control characters to None\n",
        "    control_chars = dict.fromkeys(range(0x00, 0x20), ' ')\n",
        "    control_chars.update(dict.fromkeys(range(0x7f, 0xa0), ' '))\n",
        "\n",
        "    # Translate the string using the translation table\n",
        "    cleaned_str = s.translate(dict.fromkeys(control_chars, ' '))\n",
        "\n",
        "    return cleaned_str\n",
        "\n",
        "def strip_control_characters(s):\n",
        "    # Create a translation table that maps all control characters and special characters to a space ' '\n",
        "    control_chars = dict.fromkeys(range(0x00, 0x09), ' ')  # Exclude \\n, \\r, \\f\n",
        "    control_chars.update(dict.fromkeys(range(0x0B, 0x0C), ' '))\n",
        "    control_chars.update(dict.fromkeys(range(0x0E, 0x20), ' '))\n",
        "    control_chars.update(dict.fromkeys(range(0x7f, 0xa0), ' '))\n",
        "    special_chars = dict.fromkeys(map(ord, string.punctuation.replace('\\n', '').replace('\\r', '').replace('\\f', '')), ' ')\n",
        "    control_chars.update(special_chars)\n",
        "\n",
        "    # Translate the string using the translation table\n",
        "    cleaned_str = s.translate(control_chars)"
      ],
      "metadata": {
        "id": "NOGlMd278egD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "1.   System Message\n",
        "2.   User Message\n",
        "\n"
      ],
      "metadata": {
        "id": "TqsXQmSVUKDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"\"\"\n",
        "You are  Azure Databricks data engineer.\n",
        "    You will be given tasks and asked to write spark code.\n",
        "    You will use best practices for writing code.\n",
        "    All the code will run within a sparksession. Added date and time to session name\n",
        "    Your response will be in JSON format with keys \"summary\", \"code\", \"explanation\".\n",
        "    Do not include introductory line the response.\n",
        "    Ensure that your response has no special characters.\n",
        "    Validate that your json reponse can be converted into python dictionary and confirm validation.\n",
        "  \"\"\".strip()\n",
        "\n",
        "\n",
        "user_message_content = \"\"\"\n",
        "  I will give you schema for a table. You are tasked with creating a spark session and neccessary code to create the table called orders_bronze.\n",
        "  This table will be in the database database Bookstore_catalog. Schema is bronze. Your code must create an empty table.\n",
        "  The schema is as follows\n",
        "  root\n",
        "  |-- order_id: string (nullable = true)\n",
        "  |-- order_timestamp: long (nullable = true)\n",
        "  |-- customer_id: string (nullable = true)\n",
        "  |-- quantity: long (nullable = true)\n",
        "  |-- total: integer (nullable = true)\n",
        "  |-- books: array (nullable = true)\n",
        "  |    |-- element: struct (containsNull = true)\n",
        "  |    |    |-- book_id: string (nullable = true)\n",
        "  |    |    |-- quantity: integer (nullable = true)\n",
        "  |    |    |-- subtotal: long (nullable = true)\n",
        "  |-- _rescued_data: string (nullable = true)\n",
        "  |-- file_name: string (nullable = true)\n",
        "  |-- processed_timestamp: timestamp (nullable = true)\n",
        "  \"\"\".strip()"
      ],
      "metadata": {
        "id": "CXd8CCYOLCBN"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make the call to LLMs"
      ],
      "metadata": {
        "id": "_MDSbrT9UpOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the message with variables\n",
        "response = client.messages.create(\n",
        "    model=\"claude-3-opus-20240229\",\n",
        "    max_tokens=1000,\n",
        "    temperature=0,\n",
        "    system=system_message,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": user_message_content}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Assuming you have a client setup for interaction. Ensure to configure your OpenAI client appropriately.\n",
        "\n",
        "message = response.content[0].text"
      ],
      "metadata": {
        "id": "DAKT9wxMrhGK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validate response from LLM"
      ],
      "metadata": {
        "id": "MOTbodyRUt55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54NY8U-rzqt6",
        "outputId": "7689a9fd-55b9-4847-9277-ea2c58f78653"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'anthropic.types.message.Message'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(message)\n",
        "resp_in_json = json.loads(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "8qUY0zFPy1tf",
        "outputId": "fb33632c-f6d2-48a0-a74f-027fd9fdd6c1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"summary\": \"The code creates a Spark session and an empty table called orders_bronze in the Bookstore_catalog database with the specified schema.\",\n",
            "  \"code\": \"from pyspark.sql import SparkSession\\nfrom pyspark.sql.types import StructType, StructField, StringType, LongType, IntegerType, ArrayType, TimestampType\\n\\nspark = SparkSession.builder \\\\\\n    .appName(\\\"CreateOrdersBronzeTable_20230607_1530\\\") \\\\\\n    .getOrCreate()\\n\\nschema = StructType([\\n    StructField(\\\"order_id\\\", StringType(), True),\\n    StructField(\\\"order_timestamp\\\", LongType(), True),\\n    StructField(\\\"customer_id\\\", StringType(), True),\\n    StructField(\\\"quantity\\\", LongType(), True),\\n    StructField(\\\"total\\\", IntegerType(), True),\\n    StructField(\\\"books\\\", ArrayType(StructType([\\n        StructField(\\\"book_id\\\", StringType(), True),\\n        StructField(\\\"quantity\\\", IntegerType(), True),\\n        StructField(\\\"subtotal\\\", LongType(), True)\\n    ])), True),\\n    StructField(\\\"_rescued_data\\\", StringType(), True),\\n    StructField(\\\"file_name\\\", StringType(), True),\\n    StructField(\\\"processed_timestamp\\\", TimestampType(), True)\\n])\\n\\nspark.sql(\\\"CREATE DATABASE IF NOT EXISTS Bookstore_catalog\\\")\\n\\nspark.createDataFrame([], schema) \\\\\\n    .write \\\\\\n    .format(\\\"delta\\\") \\\\\\n    .mode(\\\"overwrite\\\") \\\\\\n    .option(\\\"overwriteSchema\\\", \\\"true\\\") \\\\\\n    .saveAsTable(\\\"Bookstore_catalog.orders_bronze\\\")\",\n",
            "  \"explanation\": \"1. The necessary libraries are imported: pyspark.sql for SparkSession and pyspark.sql.types for defining the schema.\\n2. A SparkSession is created with the appName \\\"CreateOrdersBronzeTable_20230607_1530\\\".\\n3. The schema for the orders_bronze table is defined using StructType and StructField. It matches the provided schema.\\n4. The Bookstore_catalog database is created if it doesn't exist using spark.sql().\\n5. An empty DataFrame is created using spark.createDataFrame([], schema), where [] represents an empty data list and schema is the defined schema.\\n6. The empty DataFrame is written to the orders_bronze table in the Bookstore_catalog database using the Delta format.\\n7. The mode is set to \\\"overwrite\\\" to replace any existing data, and the option \\\"overwriteSchema\\\" is set to \\\"true\\\" to update the schema if needed.\\n8. The table is saved using saveAsTable() with the specified database and table name.\"\n",
            "}\n",
            "\n",
            "Validation: The JSON response can be successfully converted into a Python dictionary.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "Extra data: line 7 column 1 (char 2355)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-200edb89bd74>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresp_in_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extra data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 7 column 1 (char 2355)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_contents = create_notebook(resp_in_json, system_message, user_message_content, \"orders_bronze_notebook-t2.py\")"
      ],
      "metadata": {
        "id": "F3ZTQpLg3RiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(file_contents)"
      ],
      "metadata": {
        "id": "wjTxx8GwZV6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check into Github\n",
        "*   repository : \"cooolbabu/GoogleGemini101\"\n",
        "*   filename : \"AzureDatabricks/filename\" - specify actual filename\n",
        "*   filecontent: Contents of the file to check in\n",
        "*   tag_name: give a comment. It will show in Github\n",
        "* branch: branch name to check into. Ensure that branch already exists\n",
        "          Future TODO: if branch doesn't exist (notify, ask, process)\n",
        "\n"
      ],
      "metadata": {
        "id": "zn-veyM-U19x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "check_in_file(repo_name=\"cooolbabu/GoogleGemini101\",\n",
        "              file_path=\"AzureDatabricks/ConfigureDB/create_order_table-t1.py\",\n",
        "              file_content=file_contents,\n",
        "              content_tag='creating orders table added control characters t5',\n",
        "              branch=\"pyspark-genai-t2\")"
      ],
      "metadata": {
        "id": "ELMDUfXRBi7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def mm(graph):\n",
        "    graphbytes = graph.encode(\"utf8\")\n",
        "    base64_bytes = base64.b64encode(graphbytes)\n",
        "    base64_string = base64_bytes.decode(\"ascii\")\n",
        "    display(Image(url=\"https://mermaid.ink/img/\" + base64_string))\n",
        "\n",
        "mm(\"\"\"\n",
        "graph LR;\n",
        "    A--> B & C & D;\n",
        "    B--> A & E;\n",
        "    C--> A & E;\n",
        "    D--> A & E;\n",
        "    E--> B & C & D;\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "3oBpmydcALfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mm(\"\"\"\n",
        "   flowchart LR\n",
        "\n",
        "A[Hard] -->|Text| B(Round)\n",
        "B --> C{Decision}\n",
        "C -->|One| D[Result 1]\n",
        "C -->|Two| E[Result 2]\n",
        "   \"\"\")"
      ],
      "metadata": {
        "id": "3vyqf9_MAN5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mm(\"\"\"\n",
        "  erDiagram\n",
        "    CUSTOMER ||--o{ ORDER : PLACES\n",
        "    CUSTOMER {\n",
        "        string customer_id\n",
        "        string email\n",
        "        string PROFILE(jsonObject)\n",
        "        string updated\n",
        "    }\n",
        "    PROFILE {\n",
        "        string first_name\n",
        "        string last_name\n",
        "        string gender\n",
        "        string address\n",
        "    }\n",
        "    CUSTOMER ||--|| PROFILE : HAS\n",
        "\n",
        "    ORDER ||--|{ BOOKS_ORDERED : CONTAINS\n",
        "    ORDER {\n",
        "        string order_id\n",
        "        bigint order_timestamp\n",
        "        string customer_id\n",
        "        quanity bigint\n",
        "        double total\n",
        "        string BOOKS_ORDERED(jsonObject)\n",
        "    }\n",
        "    BOOKS_ORDERED {\n",
        "        string book_id\n",
        "        bigint quanity\n",
        "        double subtotal\n",
        "    }\n",
        "    BOOKS {\n",
        "        string book_id\n",
        "        string title\n",
        "        string author\n",
        "        string category\n",
        "        double price\n",
        "    }\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "ayg4UGXYJ7hX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}