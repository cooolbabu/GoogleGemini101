{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOad9ddn1C/WeM1utKmYnFZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cooolbabu/GoogleGemini101/blob/pyspark-genai-t1/AzureDatabricks/Boiler_code_for_Github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Package installs"
      ],
      "metadata": {
        "id": "awVI93fo_PXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install anthropic\n",
        "%pip install PyGithub"
      ],
      "metadata": {
        "id": "SUckIMaorrfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a3dcee0-bfa2-4498-cec4-6b1d3e7e84bd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.20.0-py3-none-any.whl (850 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/850.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/850.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m675.8/850.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m850.5/850.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from anthropic)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->anthropic)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->anthropic)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.16.3)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.0.7)\n",
            "Installing collected packages: h11, httpcore, httpx, anthropic\n",
            "Successfully installed anthropic-0.20.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0\n",
            "Collecting PyGithub\n",
            "  Downloading PyGithub-2.2.0-py3-none-any.whl (350 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m350.2/350.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynacl>=1.4.0 (from PyGithub)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub) (2.31.0)\n",
            "Collecting pyjwt[crypto]>=2.4.0 (from PyGithub)\n",
            "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub) (4.10.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub) (2.0.7)\n",
            "Collecting Deprecated (from PyGithub)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (42.0.5)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pynacl>=1.4.0->PyGithub) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub) (2024.2.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->PyGithub) (1.14.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub) (2.21)\n",
            "Installing collected packages: pyjwt, Deprecated, pynacl, PyGithub\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.3.0\n",
            "    Uninstalling PyJWT-2.3.0:\n",
            "      Successfully uninstalled PyJWT-2.3.0\n",
            "Successfully installed Deprecated-1.2.14 PyGithub-2.2.0 pyjwt-2.8.0 pynacl-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports, get keys, get llm client and set model to variable MODEL_NAME"
      ],
      "metadata": {
        "id": "xXANfThOTUJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from anthropic import Anthropic\n",
        "import json\n",
        "import re\n",
        "from pprint import pprint\n",
        "from google.colab import userdata\n",
        "from github import Github\n",
        "\n",
        "# Get the OpenAI API key from Colab secrets\n",
        "github_token=userdata.get('Github_Token')\n",
        "claude_api_key=userdata.get('Claude_api_key')\n",
        "# Initialize a GitHub instance\n",
        "g = Github(github_token)\n",
        "\n",
        "client = Anthropic(api_key=claude_api_key)\n",
        "MODEL_NAME = \"claude-3-opus-20240229\""
      ],
      "metadata": {
        "id": "HgzQz8VirhAw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Github helper functions\n",
        "* read_file_as_string()\n",
        "* check_in_file(repo_name, file_path, file_content, content_tag, branch)"
      ],
      "metadata": {
        "id": "2TKZOKLeXN1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file_as_string(file_path):\n",
        "    \"\"\"\n",
        "        Reads the file and return a string representation of the file contents\n",
        "\n",
        "        Parameters:\n",
        "            file_path (str): Filename including filepath\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            file_contents = file.read()\n",
        "        return file_contents\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File '{file_path}' not found.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "def check_in_file(repo_name, file_path, file_content, content_tag, branch):\n",
        "    \"\"\"\n",
        "        Checks if a specific file exists in a GitHub repository and updates it with new content if it does.\n",
        "        If the file does not exist, it creates a new file with the provided content.\n",
        "\n",
        "        This function operates on a specific branch named 'test'. If updating, it will commit the changes with a given content tag as the commit message.\n",
        "        In case the file needs to be created, it will also use the content tag as the commit message for the new file.\n",
        "\n",
        "        Parameters:\n",
        "        - repo_name (str): The name of the repository, formatted as 'username/repository'.\n",
        "        - file_path (str): The path to the file within the repository. This should include the file name and its extension.\n",
        "        - file_content (str): The content to be written to the file. This is used both for updating and creating the file.\n",
        "        - content_tag (str): A message associated with the commit used for updating or creating the file.\n",
        "        - branch (str): Github branch for the code\n",
        "\n",
        "        Behavior:\n",
        "        - If the file exists at the specified path, it updates the file with `file_content`, using `content_tag` as the commit message.\n",
        "        - If the file does not exist, it creates a new file at the specified path with `file_content`, also using `content_tag` as the commit message for creation.\n",
        "        - Upon successful update or creation, prints a success message indicating the action taken.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the repository\n",
        "    repo = g.get_repo(repo_name)\n",
        "\n",
        "    try:\n",
        "        # Get the contents of the file if it exists\n",
        "        file = repo.get_contents(file_path, ref=branch)\n",
        "\n",
        "        # Update the file\n",
        "        repo.update_file(file_path, content_tag, file_content, file.sha, branch=branch)\n",
        "        print(f\"File '{file_path}' updated successfully.\")\n",
        "    except:\n",
        "        # If the file doesn't exist, create it\n",
        "        print(f\"{file_path}/{file_content} does not exist\")\n",
        "        repo.create_file(file_path, content_tag, file_content, branch=branch)\n",
        "        print(f\"File '{file_path}' created successfully.\")\n",
        "\n",
        "def create_notebook(response, system_message, instructions, filename):\n",
        "    # Extract summary, code, and explanation from the response JSON\n",
        "    summary = response[\"summary\"]\n",
        "    code = response[\"code\"]\n",
        "    explanation = response[\"explanation\"]\n",
        "\n",
        "    # Create the notebook content\n",
        "    notebook_content = f\"\"\"# Databricks notebook source\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC # Summary\n",
        "# MAGIC {summary}\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC # Code\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "{code} U+0004\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC # Explanation\n",
        "# MAGIC {explanation}\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC # GenAI Instructions\n",
        "# MAGIC * ## AI Role\n",
        "# MAGIC {system_message}\n",
        "\n",
        "# COMMAND ----------\n",
        "# MAGIC %md\n",
        "# MAGIC * ## Instructions\n",
        "# MAGIC {instructions}\n",
        "\"\"\"\n",
        "\n",
        "    # Write the notebook content to a file\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(notebook_content)\n",
        "\n",
        "    print(f\"Notebook '{filename}' has been created.\")\n",
        "\n",
        "    return notebook_content"
      ],
      "metadata": {
        "id": "U6zhOVp3rhDW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "def convert_str_to_dict(s):\n",
        "    try:\n",
        "        d = ast.literal_eval(s)\n",
        "        if isinstance(d, dict):\n",
        "            return d\n",
        "        else:\n",
        "            raise ValueError(\"Input is not a valid dictionary string\")\n",
        "    except (ValueError, SyntaxError):\n",
        "        raise ValueError(\"Input is not a valid dictionary string\")\n",
        "\n",
        "import string\n",
        "\n",
        "def strip_control_characters(s):\n",
        "    # Create a translation table that maps all control characters to None\n",
        "    control_chars = dict.fromkeys(range(0x00, 0x20), ' ')\n",
        "    control_chars.update(dict.fromkeys(range(0x7f, 0xa0), ' '))\n",
        "\n",
        "    # Translate the string using the translation table\n",
        "    cleaned_str = s.translate(dict.fromkeys(control_chars, ' '))\n",
        "\n",
        "    return cleaned_str"
      ],
      "metadata": {
        "id": "NOGlMd278egD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "1.   System Message\n",
        "2.   User Message\n",
        "\n"
      ],
      "metadata": {
        "id": "TqsXQmSVUKDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"\"\"\n",
        "You are  Azure Databricks data engineer.\n",
        "    You will be given tasks and asked to write pyspark code.\n",
        "    You will use best practices for writing code.\n",
        "    Your response will be in JSON format with keys \"summary\", \"code\", \"explanation\".\n",
        "    Do not include introductory line the respoonse.\n",
        "  \"\"\".strip()\n",
        "\n",
        "\n",
        "user_message_content = \"\"\"\n",
        "  I will give you schema for a table. Your task is to provide pyspark code to create the table.\n",
        "  orders_bronze table schema\n",
        "  root\n",
        "  |-- order_id: string (nullable = true)\n",
        "  |-- order_timestamp: long (nullable = true)\n",
        "  |-- customer_id: string (nullable = true)\n",
        "  |-- quantity: long (nullable = true)\n",
        "  |-- total: integer (nullable = true)\n",
        "  |-- books: array (nullable = true)\n",
        "  |    |-- element: struct (containsNull = true)\n",
        "  |    |    |-- book_id: string (nullable = true)\n",
        "  |    |    |-- quantity: integer (nullable = true)\n",
        "  |    |    |-- subtotal: long (nullable = true)\n",
        "  |-- _rescued_data: string (nullable = true)\n",
        "  |-- file_name: string (nullable = true)\n",
        "  |-- processed_timestamp: timestamp (nullable = true)\n",
        "  \"\"\".strip()"
      ],
      "metadata": {
        "id": "CXd8CCYOLCBN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make the call to LLMs"
      ],
      "metadata": {
        "id": "_MDSbrT9UpOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the message with variables\n",
        "response = client.messages.create(\n",
        "    model=\"claude-3-opus-20240229\",\n",
        "    max_tokens=1000,\n",
        "    temperature=0,\n",
        "    system=system_message,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": user_message_content}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Assuming you have a client setup for interaction. Ensure to configure your OpenAI client appropriately.\n",
        "\n",
        "message = response.content[0].text"
      ],
      "metadata": {
        "id": "DAKT9wxMrhGK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validate response from LLM"
      ],
      "metadata": {
        "id": "MOTbodyRUt55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stripped_message = strip_control_characters(message)\n"
      ],
      "metadata": {
        "id": "Eiv8FviXrhNd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_contents = create_notebook(json.loads(stripped_message), system_message, user_message_content, \"orders_bronze_notebook-t2.py\")"
      ],
      "metadata": {
        "id": "F3ZTQpLg3RiI",
        "outputId": "e528703a-de45-4184-9d4a-413bcc27addd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Notebook 'orders_bronze_notebook-t2.py' has been created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(file_contents)"
      ],
      "metadata": {
        "id": "wjTxx8GwZV6k",
        "outputId": "c08c8991-3824-4476-a80d-f118101081cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Databricks notebook source\n",
            "\n",
            "# MAGIC %md\n",
            "# MAGIC # Summary\n",
            "# MAGIC The code creates a schema for the orders_bronze table using StructType and StructField classes from pyspark.sql.types, and then creates the table using createOrReplaceTempView method.\n",
            "\n",
            "# COMMAND ----------\n",
            "\n",
            "# MAGIC %md\n",
            "# MAGIC # Code\n",
            "\n",
            "# COMMAND ----------\n",
            "\n",
            "from pyspark.sql.types import StructType, StructField, StringType, LongType, IntegerType, ArrayType, TimestampType  schema = StructType([     StructField(\"order_id\", StringType(), True),     StructField(\"order_timestamp\", LongType(), True),     StructField(\"customer_id\", StringType(), True),     StructField(\"quantity\", LongType(), True),     StructField(\"total\", IntegerType(), True),     StructField(\"books\", ArrayType(         StructType([             StructField(\"book_id\", StringType(), True),             StructField(\"quantity\", IntegerType(), True),             StructField(\"subtotal\", LongType(), True)         ])     ), True),     StructField(\"_rescued_data\", StringType(), True),     StructField(\"file_name\", StringType(), True),     StructField(\"processed_timestamp\", TimestampType(), True) ])  df = spark.createDataFrame([], schema) df.createOrReplaceTempView(\"orders_bronze\") U+0004\n",
            "\n",
            "# COMMAND ----------\n",
            "\n",
            "# MAGIC %md\n",
            "# MAGIC # Explanation\n",
            "# MAGIC 1. Import necessary classes from pyspark.sql.types to define the schema. 2. Create a StructType object representing the schema of the orders_bronze table.    - Each field is defined using StructField with name, data type, and nullable flag.    - The 'books' field is an array of structs, so it's defined using ArrayType and a nested StructType. 3. Create an empty DataFrame using the defined schema. 4. Register the DataFrame as a temporary view named 'orders_bronze' using createOrReplaceTempView method.    - This allows querying the DataFrame using SQL syntax.\n",
            "\n",
            "# COMMAND ----------\n",
            "\n",
            "# MAGIC %md\n",
            "# MAGIC # GenAI Instructions\n",
            "# MAGIC * ## AI Role\n",
            "# MAGIC You are  Azure Databricks data engineer.\n",
            "    You will be given tasks and asked to write pyspark code.\n",
            "    You will use best practices for writing code.\n",
            "    Your response will be in JSON format with keys \"summary\", \"code\", \"explanation\".\n",
            "    Do not include introductory line the respoonse.\n",
            "\n",
            "# COMMAND ----------\n",
            "# MAGIC %md\n",
            "# MAGIC * ## Instructions\n",
            "# MAGIC I will give you schema for a table. Your task is to provide pyspark code to create the table. \n",
            "  orders_bronze table schema\n",
            "  root\n",
            "  |-- order_id: string (nullable = true)\n",
            "  |-- order_timestamp: long (nullable = true)\n",
            "  |-- customer_id: string (nullable = true)\n",
            "  |-- quantity: long (nullable = true)\n",
            "  |-- total: integer (nullable = true)\n",
            "  |-- books: array (nullable = true)\n",
            "  |    |-- element: struct (containsNull = true)\n",
            "  |    |    |-- book_id: string (nullable = true)\n",
            "  |    |    |-- quantity: integer (nullable = true)\n",
            "  |    |    |-- subtotal: long (nullable = true)\n",
            "  |-- _rescued_data: string (nullable = true)\n",
            "  |-- file_name: string (nullable = true)\n",
            "  |-- processed_timestamp: timestamp (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check into Github\n",
        "*   repository : \"cooolbabu/GoogleGemini101\"\n",
        "*   filename : \"AzureDatabricks/filename\" - specify actual filename\n",
        "*   filecontent: Contents of the file to check in\n",
        "*   tag_name: give a comment. It will show in Github\n",
        "* branch: branch name to check into. Ensure that branch already exists\n",
        "          Future TODO: if branch doesn't exist (notify, ask, process)\n",
        "\n"
      ],
      "metadata": {
        "id": "zn-veyM-U19x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "check_in_file(repo_name=\"cooolbabu/GoogleGemini101\",\n",
        "              file_path=\"AzureDatabricks/ConfigureDB/create_order_table-t5.py\",\n",
        "              file_content=file_contents,\n",
        "              content_tag='creating orders table added control characters t5',\n",
        "              branch=\"pyspark-genai-t1\")"
      ],
      "metadata": {
        "id": "ELMDUfXRBi7V",
        "outputId": "cd7feebe-db76-4968-b5f2-5b1f84972e69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AzureDatabricks/ConfigureDB/create_order_table-t5.py/# Databricks notebook source\n",
            "\n",
            "# MAGIC %md\n",
            "# MAGIC # Summary\n",
            "# MAGIC The code creates a schema for the orders_bronze table using StructType and StructField classes from pyspark.sql.types, and then creates the table using createOrReplaceTempView method.\n",
            "\n",
            "# COMMAND ----------\n",
            "\n",
            "# MAGIC %md\n",
            "# MAGIC # Code\n",
            "\n",
            "# COMMAND ----------\n",
            "\n",
            "from pyspark.sql.types import StructType, StructField, StringType, LongType, IntegerType, ArrayType, TimestampType  schema = StructType([     StructField(\"order_id\", StringType(), True),     StructField(\"order_timestamp\", LongType(), True),     StructField(\"customer_id\", StringType(), True),     StructField(\"quantity\", LongType(), True),     StructField(\"total\", IntegerType(), True),     StructField(\"books\", ArrayType(         StructType([             StructField(\"book_id\", StringType(), True),             StructField(\"quantity\", IntegerType(), True),             StructField(\"subtotal\", LongType(), True)         ])     ), True),     StructField(\"_rescued_data\", StringType(), True),     StructField(\"file_name\", StringType(), True),     StructField(\"processed_timestamp\", TimestampType(), True) ])  df = spark.createDataFrame([], schema) df.createOrReplaceTempView(\"orders_bronze\") U+0004\n",
            "\n",
            "# COMMAND ----------\n",
            "\n",
            "# MAGIC %md\n",
            "# MAGIC # Explanation\n",
            "# MAGIC 1. Import necessary classes from pyspark.sql.types to define the schema. 2. Create a StructType object representing the schema of the orders_bronze table.    - Each field is defined using StructField with name, data type, and nullable flag.    - The 'books' field is an array of structs, so it's defined using ArrayType and a nested StructType. 3. Create an empty DataFrame using the defined schema. 4. Register the DataFrame as a temporary view named 'orders_bronze' using createOrReplaceTempView method.    - This allows querying the DataFrame using SQL syntax.\n",
            "\n",
            "# COMMAND ----------\n",
            "\n",
            "# MAGIC %md\n",
            "# MAGIC # GenAI Instructions\n",
            "# MAGIC * ## AI Role\n",
            "# MAGIC You are  Azure Databricks data engineer.\n",
            "    You will be given tasks and asked to write pyspark code.\n",
            "    You will use best practices for writing code.\n",
            "    Your response will be in JSON format with keys \"summary\", \"code\", \"explanation\".\n",
            "    Do not include introductory line the respoonse.\n",
            "\n",
            "# COMMAND ----------\n",
            "# MAGIC %md\n",
            "# MAGIC * ## Instructions\n",
            "# MAGIC I will give you schema for a table. Your task is to provide pyspark code to create the table. \n",
            "  orders_bronze table schema\n",
            "  root\n",
            "  |-- order_id: string (nullable = true)\n",
            "  |-- order_timestamp: long (nullable = true)\n",
            "  |-- customer_id: string (nullable = true)\n",
            "  |-- quantity: long (nullable = true)\n",
            "  |-- total: integer (nullable = true)\n",
            "  |-- books: array (nullable = true)\n",
            "  |    |-- element: struct (containsNull = true)\n",
            "  |    |    |-- book_id: string (nullable = true)\n",
            "  |    |    |-- quantity: integer (nullable = true)\n",
            "  |    |    |-- subtotal: long (nullable = true)\n",
            "  |-- _rescued_data: string (nullable = true)\n",
            "  |-- file_name: string (nullable = true)\n",
            "  |-- processed_timestamp: timestamp (nullable = true)\n",
            " does not exist\n",
            "File 'AzureDatabricks/ConfigureDB/create_order_table-t5.py' created successfully.\n"
          ]
        }
      ]
    }
  ]
}